{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9eSJ2FO6NGzP"
      },
      "outputs": [],
      "source": [
        "import ast, random, spacy\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from spacy.tokens import DocBin\n",
        "from spacy.training import Example\n",
        "from spacy.util import minibatch, compounding\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Scorpio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CSV_PATH = \"/content/NER_Dataset.csv\"\n",
        "df = pd.read_csv(CSV_PATH, encoding=\"latin-1\")\n",
        "\n",
        "df[\"tokens\"] = df[\"Word\"].apply(ast.literal_eval)\n",
        "df[\"tags\"]   = df[\"Tag\"].apply(ast.literal_eval)"
      ],
      "metadata": {
        "id": "I7nHSl6qOEdH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp  = spacy.blank(\"en\")\n",
        "ner  = nlp.add_pipe(\"ner\")\n",
        "\n",
        "labels = sorted({t.split(\"-\",1)[1] for row in df.tags for t in row if t != \"O\"})\n",
        "for lab in labels:\n",
        "    ner.add_label(lab)"
      ],
      "metadata": {
        "id": "eReV5iFsOMLj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def row_to_example(tokens, tags):\n",
        "    text, offset, spans = \"\", 0, []\n",
        "    for tok, tag in zip(tokens, tags):\n",
        "        if text:\n",
        "            text += \" \"\n",
        "            offset += 1\n",
        "        start = offset\n",
        "        text += tok\n",
        "        end = offset + len(tok)\n",
        "        if tag != \"O\":\n",
        "            spans.append((start, end, tag.split(\"-\",1)[1]))\n",
        "        offset = end\n",
        "    doc = nlp.make_doc(text)\n",
        "    doc.ents = [doc.char_span(s, e, label=l, alignment_mode=\"contract\")\n",
        "                for s,e,l in spans if doc.char_span(s, e, label=l)]\n",
        "    return Example.from_dict(doc, {\"entities\": spans})\n",
        "\n",
        "examples = [row_to_example(toks, tags)\n",
        "            for toks, tags in zip(df.tokens, df.tags)]"
      ],
      "metadata": {
        "id": "FcJdx6JYOOwg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_exs, tmp = train_test_split(examples, test_size=0.2,\n",
        "                                      random_state=42, shuffle=True)\n",
        "dev_exs, test_exs  = train_test_split(tmp, test_size=0.5,\n",
        "                                      random_state=42, shuffle=True)"
      ],
      "metadata": {
        "id": "ZfROSCu8OR8V"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, exs in [(\"train\", train_exs), (\"dev\", dev_exs), (\"test\", test_exs)]:\n",
        "    db = DocBin(store_user_data=True)\n",
        "    for ex in exs:\n",
        "        db.add(ex.reference)\n",
        "    db.to_disk(f\"{name}.spacy\")"
      ],
      "metadata": {
        "id": "HIyBewgMOYcF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = nlp.initialize(get_examples=lambda: train_exs)\n",
        "N_EPOCHS  = 37\n",
        "\n",
        "for epoch in range(1, N_EPOCHS + 1):\n",
        "    random.shuffle(train_exs)\n",
        "    losses = {}\n",
        "\n",
        "    for batch in minibatch(train_exs, size=compounding(4.0, 32.0, 1.5)):\n",
        "        nlp.update(batch, sgd=optimizer, drop=0.2, losses=losses)\n",
        "\n",
        "    dev_examples = [Example(nlp(ex.reference.text), ex.reference)\n",
        "                    for ex in dev_exs]\n",
        "    dev_scores = nlp.evaluate(dev_examples)\n",
        "\n",
        "    print(\n",
        "        f\"epoch {epoch:02d}  \"\n",
        "        f\"loss={losses['ner']:.3f}  \"\n",
        "        f\"P={dev_scores['ents_p']:.2f}  \"\n",
        "        f\"R={dev_scores['ents_r']:.2f}  \"\n",
        "        f\"F1={dev_scores['ents_f']:.2f}\"\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwH62PiSrEzG",
        "outputId": "d8aa450d-8910-48f8-9b75-4dc2dc2b8fa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 01  loss=61284.378  P=0.85  R=0.84  F1=0.85\n",
            "epoch 02  loss=40865.917  P=0.86  R=0.86  F1=0.86\n",
            "epoch 03  loss=36770.088  P=0.87  R=0.85  F1=0.86\n",
            "epoch 04  loss=34194.790  P=0.87  R=0.86  F1=0.87\n",
            "epoch 05  loss=32499.618  P=0.87  R=0.86  F1=0.86\n",
            "epoch 06  loss=30931.744  P=0.87  R=0.85  F1=0.86\n",
            "epoch 07  loss=29772.791  P=0.88  R=0.86  F1=0.87\n",
            "epoch 08  loss=28540.543  P=0.88  R=0.86  F1=0.87\n",
            "epoch 09  loss=27717.044  P=0.87  R=0.87  F1=0.87\n",
            "epoch 10  loss=26981.188  P=0.87  R=0.88  F1=0.87\n",
            "epoch 11  loss=26049.764  P=0.88  R=0.87  F1=0.87\n",
            "epoch 12  loss=25342.150  P=0.88  R=0.87  F1=0.88\n",
            "epoch 13  loss=25053.035  P=0.88  R=0.87  F1=0.88\n",
            "epoch 14  loss=24272.777  P=0.88  R=0.87  F1=0.87\n",
            "epoch 15  loss=24019.191  P=0.88  R=0.87  F1=0.88\n",
            "epoch 16  loss=23758.517  P=0.88  R=0.86  F1=0.87\n",
            "epoch 17  loss=22932.794  P=0.88  R=0.87  F1=0.87\n",
            "epoch 18  loss=22706.040  P=0.87  R=0.87  F1=0.87\n",
            "epoch 19  loss=22285.696  P=0.88  R=0.87  F1=0.87\n",
            "epoch 20  loss=22076.073  P=0.88  R=0.87  F1=0.87\n",
            "epoch 21  loss=21827.875  P=0.88  R=0.88  F1=0.88\n",
            "epoch 22  loss=21475.015  P=0.88  R=0.87  F1=0.88\n",
            "epoch 23  loss=21251.983  P=0.87  R=0.87  F1=0.87\n",
            "epoch 24  loss=21088.358  P=0.88  R=0.87  F1=0.87\n",
            "epoch 25  loss=20600.513  P=0.88  R=0.86  F1=0.87\n",
            "epoch 26  loss=20382.578  P=0.87  R=0.87  F1=0.87\n",
            "epoch 27  loss=20137.234  P=0.87  R=0.87  F1=0.87\n",
            "epoch 28  loss=20013.516  P=0.87  R=0.88  F1=0.87\n",
            "epoch 29  loss=19700.743  P=0.87  R=0.87  F1=0.87\n",
            "epoch 30  loss=19893.982  P=0.88  R=0.87  F1=0.87\n",
            "epoch 31  loss=19321.334  P=0.88  R=0.87  F1=0.88\n",
            "epoch 32  loss=19228.873  P=0.88  R=0.87  F1=0.88\n",
            "epoch 33  loss=19071.235  P=0.87  R=0.88  F1=0.88\n",
            "epoch 34  loss=18901.478  P=0.87  R=0.88  F1=0.87\n",
            "epoch 35  loss=18655.764  P=0.87  R=0.88  F1=0.88\n",
            "epoch 36  loss=18410.063  P=0.88  R=0.87  F1=0.87\n",
            "epoch 37  loss=18355.927  P=0.86  R=0.88  F1=0.87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_score = nlp.evaluate([Example(nlp(ex.reference.text), ex.reference)\n",
        "                           for ex in test_exs])\n",
        "print(\"TEST  F1={ents_f:.2f}  P={ents_p:.2f}  R={ents_r:.2f}\".format(**test_score))"
      ],
      "metadata": {
        "id": "jzDgIatROonb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30106e1e-34b2-4354-8c81-b63ada9a90d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST  F1=0.87  P=0.87  R=0.88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out_dir = Path(\"best_ner_model\")\n",
        "nlp.to_disk(out_dir)\n",
        "print(f\"model saved to {out_dir.resolve()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bq0Zcp3ZUvCv",
        "outputId": "62a497b9-2b90-4166-dca6-c2e06cce28f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model saved to /content/best_ner_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creates a small, human-editable template\n",
        "!python -m spacy init config base_config.cfg \\\n",
        "       --lang en \\\n",
        "       --pipeline ner \\\n",
        "       --optimize efficiency\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFe4cNwNU4mg",
        "outputId": "b64666c2-5e41-40a9-ead0-fecebd773000"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;3m⚠ To generate a more effective transformer-based config (GPU-only),\n",
            "install the spacy-transformers package and re-run this command. The config\n",
            "generated now does not use transformers.\u001b[0m\n",
            "\u001b[38;5;4mℹ Generated config template specific for your use case\u001b[0m\n",
            "- Language: en\n",
            "- Pipeline: ner\n",
            "- Optimize for: efficiency\n",
            "- Hardware: CPU\n",
            "- Transformer: None\n",
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "base_config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train base_config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy init fill-config base_config.cfg config.cfg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOMHwj7bVvbp",
        "outputId": "6121b7b5-ecc4-4c6a-df54-a74ff703130d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;3m⚠ Nothing to auto-fill: base config is already complete\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy train config.cfg \\\n",
        "     --output ./output \\\n",
        "     --paths.train ./train.spacy \\\n",
        "     --paths.dev   ./dev.spacy \\\n",
        "     --gpu-id 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVLxvLmpaUr-",
        "outputId": "7512ed0b-db55-451e-a982-244e1370f6f1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Created output directory: output\u001b[0m\n",
            "\u001b[38;5;4mℹ Saving to output directory: output\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
            "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  ------------  --------  ------  ------  ------  ------\n",
            "  0       0          0.00     51.41    0.10    2.09    0.05    0.00\n",
            "  0     200        105.37   3260.95   63.99   66.04   62.05    0.64\n",
            "  0     400        277.54   2150.17   76.78   77.47   76.10    0.77\n",
            "  0     600        198.07   2175.77   78.36   79.13   77.61    0.78\n",
            "  0     800        253.81   2575.24   81.39   83.06   79.79    0.81\n",
            "  0    1000        277.44   2795.69   82.23   84.02   80.52    0.82\n",
            "  0    1200        324.41   3161.00   82.74   84.02   81.51    0.83\n",
            "  0    1400        393.23   3683.37   83.03   84.02   82.06    0.83\n",
            "  0    1600        454.40   4304.35   84.58   86.01   83.20    0.85\n",
            "  0    1800        563.07   5240.94   85.19   84.86   85.53    0.85\n",
            "  0    2000        656.57   6075.23   85.73   86.44   85.03    0.86\n",
            "  0    2200        785.26   7072.00   85.96   85.73   86.19    0.86\n",
            "  1    2400        984.31   7727.44   85.94   85.97   85.91    0.86\n",
            "  1    2600       1030.24   7488.78   86.50   87.31   85.71    0.87\n",
            "  1    2800       1119.36   7687.29   86.57   87.21   85.94    0.87\n",
            "  1    3000       1087.06   7536.24   86.92   87.57   86.28    0.87\n",
            "  2    3200       1089.81   7268.18   86.66   87.51   85.83    0.87\n",
            "  2    3400       1181.23   6588.51   86.65   87.39   85.91    0.87\n",
            "  2    3600       1232.58   6516.20   86.83   87.75   85.93    0.87\n",
            "  2    3800       1210.03   6768.39   86.50   86.38   86.62    0.86\n",
            "  2    4000       1257.56   6939.71   87.17   87.99   86.36    0.87\n",
            "  3    4200       1229.40   5943.76   86.85   87.14   86.57    0.87\n",
            "  3    4400       1348.41   6068.93   86.88   86.74   87.02    0.87\n",
            "  3    4600       1295.92   6196.18   86.55   86.25   86.86    0.87\n",
            "  3    4800       1277.77   6224.03   87.14   86.81   87.47    0.87\n",
            "  4    5000       1350.70   5644.82   86.73   86.87   86.59    0.87\n",
            "  4    5200       1496.20   5552.97   86.76   87.24   86.29    0.87\n",
            "  4    5400       1432.71   5712.50   87.05   87.76   86.35    0.87\n",
            "  4    5600       1504.15   5950.02   87.02   87.17   86.86    0.87\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "output/model-last\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy evaluate output/model-best ./test.spacy --output metrics.json --gpu-id 0"
      ],
      "metadata": {
        "id": "X-n14wAljb6k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09b57eee-766d-46d4-ea59-ad976c942ba5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "================================== Results ==================================\u001b[0m\n",
            "\n",
            "TOK     100.00\n",
            "NER P   88.66 \n",
            "NER R   86.43 \n",
            "NER F   87.53 \n",
            "SPEED   33856 \n",
            "\n",
            "\u001b[1m\n",
            "=============================== NER (per type) ===============================\u001b[0m\n",
            "\n",
            "          P       R       F\n",
            "gpe   96.29   93.59   94.92\n",
            "geo   86.94   91.35   89.09\n",
            "tim   94.78   87.85   91.19\n",
            "per   88.24   89.92   89.07\n",
            "org   84.09   76.81   80.28\n",
            "eve   65.22   25.86   37.04\n",
            "nat   60.00   33.33   42.86\n",
            "art    0.00    0.00    0.00\n",
            "\n",
            "\u001b[38;5;2m✔ Saved results to metrics.json\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ld = spacy.load(\"./output/model-best\")"
      ],
      "metadata": {
        "id": "U-YDBaKktnq-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Elon Musk founded Tesla\"\n",
        "doc = ld(text)\n",
        "\n",
        "\n",
        "for entity in doc.ents:\n",
        "    print(entity.text, entity.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LYPWkpluCe8",
        "outputId": "7368d285-22f1-4223-da18-0320abc3fb12"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elon per\n",
            "Musk per\n",
            "Tesla geo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uUk1i_NTuLc7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}